# Architecture Analysis & Recommendations

**Project**: Vocalize - Real-Time Speech Transcription  
**Date**: January 15, 2026  
**Technology Stack**: React + FastAPI + Whisper + LiveKit/WebSocket

---

## üèóÔ∏è Current Architecture (Hybrid Approach)

### Overview
The current implementation uses **BOTH** LiveKit and WebSocket connections:

![Current Hybrid Architecture](./images/current_hybrid_architecture.png)

### Components

**Frontend:**
- `useLiveKit.ts`: Manages both LiveKit room and WebSocket
- LiveKit Client: Creates room, publishes audio track
- WebSocket: Sends audio chunks, receives transcripts
- MediaRecorder: Captures audio in WebM format

**Backend:**
- FastAPI: Serves API and WebSocket endpoint
- WebSocket Handler: Receives audio, processes with Whisper
- Whisper Model: `base` model with CPU inference (INT8)
- FFmpeg: Converts WebM ‚Üí WAV for Whisper

### Data Flow

1. User clicks Record
2. Frontend establishes LiveKit room + WebSocket
3. Microphone audio captured via LiveKit track
4. Audio chunks (3-second intervals) sent over WebSocket
5. Backend converts WebM ‚Üí WAV ‚Üí Whisper transcription
6. Transcript sent back over WebSocket
7. UI displays result

### Issues with Current Approach

‚ö†Ô∏è **Redundancy:**
- LiveKit creates rooms but isn't used for transcription
- WebSocket does all the actual work
- Two connections for what one could do

‚ö†Ô∏è **Complexity:**
- More code to maintain
- LiveKit costs (cloud hosting)
- Harder to debug connection issues

‚ö†Ô∏è **Non-Standard:**
- LiveKit is designed for agent-based transcription
- Current usage doesn't leverage LiveKit's strengths

---

## üìä Alternative Approaches

### Option 1: LiveKit Agents Pattern (Standard)

![LiveKit Agents Architecture](./images/livekit_agents_architecture.png)

**Architecture:**

**How it works:**
1. Frontend publishes audio to LiveKit room
2. LiveKit Agent subscribes to audio track
3. Agent processes with Whisper
4. Results sent via LiveKit Data Channel
5. Frontend receives transcripts

**Pros:**
- ‚úÖ Standard LiveKit pattern
- ‚úÖ Built-in recording capabilities
- ‚úÖ Multi-user support
- ‚úÖ Scalable infrastructure
- ‚úÖ Security features (E2E encryption)

**Cons:**
- ‚ùå More complex setup
- ‚ùå LiveKit cloud costs
- ‚ùå Heavier infrastructure
- ‚ùå Overkill for single-user apps

**Best for:**
- Multi-user rooms
- Production applications
- Need recording/playback
- Enterprise features required

---

### Option 2: WebSocket-Only Pattern (Recommended)

![System Architecture](./images/system_architecture_flow.png)

**Architecture:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Backend      ‚îÇ
‚îÇ         ‚îÇ WebSocket‚îÇ              ‚îÇ
‚îÇ         ‚îÇ         ‚îÇ ‚îú‚îÄWebSocket  ‚îÇ
‚îÇ         ‚îÇ         ‚îÇ ‚îú‚îÄWhisper    ‚îÇ
‚îÇ         ‚îÇ         ‚îÇ ‚îî‚îÄFFmpeg     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**How it works:**
1. Frontend gets microphone with `getUserMedia()`
2. Audio chunks sent over WebSocket
3. Backend processes with Whisper
4. Transcripts returned over same WebSocket
5. Single persistent connection

**Pros:**
- ‚úÖ **Simplest architecture**
- ‚úÖ **Lowest latency** (direct connection)
- ‚úÖ **No external dependencies**
- ‚úÖ **Easy to debug**
- ‚úÖ **Lower costs** (no LiveKit)
- ‚úÖ **Perfect for speech practice**

**Cons:**
- ‚ùå No built-in multi-user support
- ‚ùå No built-in recording (can add manually)
- ‚ùå Manual connection management

**Best for:**
- ‚úÖ **Speech practice apps** (your use case!)
- Single-user applications
- Prototypes & MVPs
- Cost-sensitive projects

---

## üéØ Recommendation

### For Vocalize (Speech Practice App)

**Use: WebSocket-Only Approach**

**Reasons:**

1. **Simplicity**: 50% less code, easier maintenance
2. **Perfect Fit**: Single-user speech practice doesn't need LiveKit features
3. **Performance**: Lower latency, fewer network hops
4. **Cost**: No LiveKit hosting costs
5. **Your Current Code**: WebSocket already works perfectly!

### Migration Path

**Remove:**
- LiveKit client dependency
- Room creation/management code
- LiveKit token generation API

**Keep:**
- WebSocket connection (already working)
- Whisper transcription backend
- Current UI/UX

**Add:**
- Direct `getUserMedia()` for microphone
- Simplified connection management

---

## üîß Implementation Comparison

### Current (Hybrid)

**Frontend Dependencies:**
```json
{
  "livekit-client": "^2.x",
  // ...other deps
}
```

**Connection Code:**
```typescript
// Create LiveKit room
const room = new Room();
await room.connect(url, token);

// Also create WebSocket
const ws = new WebSocket('/ws');

// Send audio via WebSocket (not LiveKit!)
ws.send(audioChunk);
```

**Issues:**
- LiveKit room created but not used
- WebSocket does all the work
- Redundant connections

---

### Recommended (WebSocket-Only)

**Frontend Dependencies:**
```json
{
  // No LiveKit needed!
}
```

**Connection Code:**
```typescript
// Simple WebSocket
const ws = new WebSocket('/ws');

// Direct microphone access
const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
const recorder = new MediaRecorder(stream);

// Send audio chunks
recorder.ondataavailable = (e) => ws.send(e.data);
```

**Benefits:**
- ‚úÖ Cleaner code
- ‚úÖ One connection
- ‚úÖ Simpler logic

---

## üìà Performance Metrics

### Current Metrics (Optimized)

| Metric | Value | Notes |
|--------|-------|-------|
| **Connection Setup** | ~3-5 seconds | LiveKit + WebSocket |
| **Transcription TAT** | 2-5 seconds | Optimized Whisper |
| **Total Latency** | 5-10 seconds | Speech ‚Üí Transcript |
| **Memory Usage** | ~500MB | Base model + connections |
| **Chunk Size** | 40KB minimum | Filter small chunks |

### Optimizations Applied

1. **Whisper Speed:**
   - Disabled compression ratio checks
   - Disabled quality retries
   - Single-pass decoding (temperature=0)
   - Result: 10x faster (37s ‚Üí 3s)

2. **Connection Management:**
   - Persistent room (no reconnection)
   - Instant record/stop toggle
   - Smart chunk filtering (>40KB)

3. **UI Performance:**
   - Animated audio visualizer (60fps)
   - Color-coded levels
   - Real-time percentage display

---

## üõ†Ô∏è Technology Stack Details

### Backend

**Framework:** FastAPI
```python
# WebSocket endpoint
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    # Handle audio chunks
    # Process with Whisper
    # Return transcripts
```

**Whisper Configuration:**
```python
WhisperModel(
    "base",  # 140MB, balanced accuracy/speed
    device="cpu",
    compute_type="int8",  # Quantized for speed
    # Optimizations:
    compression_ratio_threshold=None,  # No retries
    temperature=0.0,  # Deterministic
    beam_size=1  # Fast decoding
)
```

**Audio Processing:**
```
WebM (from browser) ‚Üí FFmpeg ‚Üí WAV (16kHz, mono) ‚Üí Whisper
```

### Frontend

**Framework:** React + TypeScript + Vite

**UI Library:** Tailwind CSS + shadcn/ui

**State Management:**
- Custom hooks (`useLiveKit`)
- React state for UI
- No external state library needed

**Audio Capture:**
- MediaRecorder API (WebM/Opus codec)
- 3-second chunks
- Real-time level monitoring

---

## üîê Security Considerations

### Current Security

**LiveKit:**
- ‚úÖ JWT token authentication
- ‚úÖ E2E encryption (not used)
- ‚úÖ Room isolation

**WebSocket:**
- ‚ö†Ô∏è No built-in authentication
- ‚ö†Ô∏è No encryption (use WSS in production)

### Recommendations

1. **Use WSS** (WebSocket Secure) in production
2. **Add authentication** to WebSocket connection
3. **Rate limiting** to prevent abuse
4. **Input validation** for audio chunks
5. **CORS** properly configured

---

## üí∞ Cost Analysis

### LiveKit Costs (Current)

**Free Tier:**
- 10,000 participant minutes/month
- Good for development

**Paid:**
- ~$0.004/minute after free tier
- Additional costs for recording, egress

### WebSocket-Only Costs

**Infrastructure:**
- Server hosting only
- No per-minute charges
- Predictable costs

**Estimated Savings:**
- Development: $0 (both free)
- Production (1000 users): **$200-500/month saved**

---

## üöÄ Future Considerations

### If You Need Multi-User Features

**Then** switch to LiveKit Agents Pattern:
- Multiple participants in room
- Collaborative transcription
- Shared playback
- Recording storage

### If Staying Single-User

**Enhance** WebSocket-Only:
- Add authentication layer
- Implement session management
- Add transcript storage (database)
- Export functionality (already done!)

---

## üìù Decision Matrix

| Use Case | Current | LiveKit | WebSocket |
|----------|---------|---------|-----------|
| **Single-user speech practice** | ‚ö†Ô∏è Overkill | ‚ùå Overkill | ‚úÖ **Perfect** |
| **Multi-user rooms** | ‚ö†Ô∏è Half-implemented | ‚úÖ **Best** | ‚ùå Need extra work |
| **Simple prototype** | ‚ùå Complex | ‚ùå Complex | ‚úÖ **Best** |
| **Enterprise app** | ‚ö†Ô∏è Mixed | ‚úÖ **Best** | ‚ö†Ô∏è Need features |
| **Low budget** | ‚ö†Ô∏è Medium cost | ‚ùå Higher cost | ‚úÖ **Lowest** |
| **Quick to market** | ‚ö†Ô∏è Moderate | ‚ùå Slower | ‚úÖ **Fastest** |

---

## ‚úÖ Final Recommendation

### For Vocalize Project:

**Migrate to WebSocket-Only Architecture**

**Why:**
1. Matches your use case perfectly (single-user speech practice)
2. Simpler = faster development & maintenance
3. Lower costs (no LiveKit fees)
4. Better performance (lower latency)
5. Your WebSocket code already works great!

**Timeline:**
- Refactoring: 2-4 hours
- Testing: 1-2 hours
- Result: Cleaner, faster, simpler application

**Risk Assessment:**
- Risk: **Low** (WebSocket already proven to work)
- Effort: **Medium** (code removal + minor changes)
- Benefit: **High** (simplicity + cost savings)

---

## üìö References

- [LiveKit Agents Documentation](https://docs.livekit.io/agents/)
- [Faster-Whisper GitHub](https://github.com/guillaumekln/faster-whisper)
- [WebSocket API MDN](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [MediaRecorder API](https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder)

---

**Document Version**: 1.0  
**Last Updated**: January 15, 2026  
**Author**: Development Team
